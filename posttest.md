#### Please attempt the following questions

<br>
Q1. Which step is not involved in the KNN algorithm?<br>
a. Training phase <br>
b. Testing phase <br>
c. Decision boundary optimization <br>
d. Evaluation phase <br>
<br>

Q2. What does the value of K represent in the KNN algorithm?<br>
a. The number of features in the dataset. <br>
b. The distance metric used to calculate similarities. <br>
c. The number of nearest neighbors to consider for classification. <br>
d. The number of training instances in the dataset. <br>
<br>

Q3. In the KNN algorithm, how is the class of a new instance determined?<br>
a. By taking the weighted average of the classes of its k nearest neighbors. <br>
b. By selecting the class of the nearest neighbor with the highest confidence score. <br>
c. By choosing the class of the majority of its k nearest neighbors. <br>
d. By fitting a decision boundary using logistic regression. <br>
<br>

Q4. Which of the following is a disadvantage of the KNN algorithm?<br>
a. It is not suitable for multi-class classification. <br>
b. It requires a significant amount of memory to store the entire training dataset. <br>
c. It assumes that the data instances are linearly separable. <br>
d. It is sensitive to the feature scaling of the input data. <br>
<br>

Q5. Which of the following statements about the decision boundary in K-Nearest Neighbors (KNN) algorithm is true?<br>
a. The decision boundary in KNN is always linear. <br>
b. The decision boundary in KNN can be non-linear. <br>
c. The decision boundary in KNN depends only on the value of K. <br>
d. The decision boundary in KNN is determined by the feature space dimensionality. <br>
<br>



